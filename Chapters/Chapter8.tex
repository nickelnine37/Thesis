\chapter{Conclusions} % Main chapter title

\label{chap:conclusions} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 8. \emph{Conclusions}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

In this thesis, we have developed several novel Graph Signal Processing (GSP) models designed to estimate arbitrary missing values within multivariate graph signals. This final chapter gives an overview of all the models presented in this thesis, followed by a discussion of some of their key characteristics. In addition, we highlight areas for improvement and give an outlook on possible future work in this area. 

\section{Summary of models}

\subsection*{Graph Signal Reconstruction (GSR)}

In \cref{chap:gsr_2d}, we addressed the topic of Graph Signal Reconstruction on Cartesian product graphs. 

\subsection*{Kernel Graph Regression (KGR)}

\subsection*{Regression with Network Cohesion (RNC)}

\subsection*{Kernel Graph Regression with Network Cohesion (KG-RNC)}

\subsection*{Logistic Graph Signal Reconstruction (L-GSR)}

\subsection*{Logistic Kernel Graph Regression (L-KGR)}

\subsection*{Logistic Regression with Network Cohesion (L-RNC)}

\subsection*{Logistic Kernel Graph Regression with Network Cohesion (L-KGRNC)}



\section{Discussion}

\subsection*{Scalability}

Distributed methods, incomplete eigendecomposition of $\LL$, not possible for kernel models (common problem with GPs). 

\subsection*{Hyperparameter selection}

\section{Future work}

Directed graphs