% Appendix A

\chapter{Proofs} % Main appendix title

\label{AppendixA} % For referencing this appendix elsewhere, use \ref{AppendixA}

\lhead{Appendix A. \emph{Proofs}} % This is for the header on each page - perhaps a shortened title

\begin{theorem}

    \label{the:F_posterior}
    The posterior distribution for $\F$ is given by 

    \begin{equation}
            \Vecc{\F} \, | \, \Y \sim \mathcal{N} \big(\SIG \, \Vecc{\Y}, \; \SIG \big)
        \end{equation}
        
        \noindent where 
        
        \begin{equation}
            \SIG = \Big(\Diag{\vecc{\Ss}} + \gamma  \HH^{-2}\Big)^{-1}
        \end{equation}

\end{theorem}

\begin{proof}
    Consider the matrix $\Ss_{\epsilon}$ defined in the following manner. 
    
    \begin{equation}
        (\Ss_{\epsilon})_{nt} = \begin{cases}
            1 & \text{if} \;\; (n, t) \in \mathcal{S} \\
            \epsilon & \text{otherwise}
        \end{cases}
    \end{equation}

    We can use this definition to rewrite equation \ref{eq:Y_given_F} for the probability distribution of $\Y | \F$.

    \begin{equation}
        \Vecc{\Y} \, | \, \F \, \sim \, \lim_{\epsilon \rightarrow 0} \, \Bigg[ \, \mathcal{N}\Big(\vecc{\Ss_{\epsilon} \circ \F}, \; \Diag{\vecc{\Ss_{\epsilon}}}\Big) \, \Bigg]
    \end{equation}

    In this way, the negative log-likelihood of an observation $\Y | \F$ is given by 

    \begin{equation}
        \label{eq:log_prob_1}
        - \log \pi(\Y | \F) = \lim_{\epsilon \rightarrow 0} \, \Bigg[  \frac{1}{2} \vecc{\Ss_{\epsilon} \circ \F - \Y}^\top \Diag{\vecc{\Ss_{\epsilon}}}^{-1} \vecc{\Ss_{\epsilon} \circ \F - \Y}\, \Bigg]
    \end{equation}

    up to an additive constant which does not depend on $\F$. Note that, since $\Y = \Ss_{\epsilon}  \circ \Y$, we can rewrite $\vecc{\Ss_{\epsilon} \circ \F - \Y}$ as 

    \begin{align}
        \vecc{\Ss_{\epsilon} \circ \F - \Y} &= \Vecc{\Ss_{\epsilon} \circ  (\F - \Y)}  \notag \\
        &= \Diag{\vecc{\Ss_{\epsilon}}} \vecc{\F - \Y}
    \end{align}

    Therefore, equation \ref{eq:log_prob_1} can be rewritten as 

    \begin{align}
        - \log \pi(\Y | \F) &= \lim_{\epsilon \rightarrow 0} \, \Bigg[  \frac{1}{2} \vecc{\F - \Y}^\top \Diag{\vecc{\Ss_{\epsilon}}} \, \vecc{\F - \Y}\, \Bigg] \notag \\[0.2cm]
        &= \frac{1}{2} \vecc{\F - \Y}^\top \Diag{\vecc{\Ss}} \, \vecc{\F - \Y}
    \end{align}

    Now consider the full log-posterior. Using Bayes rule, this can be written as 

    \begin{multline}
        -\log \pi\big(\vecc{\F} \, | \, \Y \big) = \frac{1}{2} \vecc{\F - \Y}^\top \Diag{\vecc{\Ss}} \, \vecc{\F - \Y} \; + \\ \frac{\gamma}{2} \vecc{\F }^\top\HH^{-2} \, \vecc{\F}
    \end{multline}

    Up to an additive constant not dependent $\F$, this can be written as 

    \begin{equation}
        -\log \pi\big(\vecc{\F} \, | \, \Y \big) = \frac{1}{2} \Big( \vecc{\F}^\top \big( \Diag{\vecc{\Ss}} + \gamma \HH^{-2}\big) \vecc{\F} - 2 \, \vecc{\Y}^\top \F \Big)
    \end{equation}

    Using the conjugacy of the normal distribution, by direct inspection we can conclude that the posterior covariance is given by 

    \begin{equation}
        \SIG = \Big( \Diag{\vecc{\Ss}} + \gamma \HH^{-2} \Big)^{-1}
    \end{equation}

    and that the posterior mean is given by $\SIG \, \vecc{\Y}$. 

\end{proof}